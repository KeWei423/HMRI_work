{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIGGO TO DO:\n",
    "# trash bin for each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Possible names for each sequence\n",
    "\n",
    "# \"3D_T1\": ['*SAG*T1*NII', '*SAG*FSPGR*3D*NII']\n",
    "# \"FLAIR\": <ID>_{SAG | AX | COR}_[T1_ | T2_][3D_]FLAIR_[MIP_ | RECON_AVG_]<DOE>[_<tag>].nii\n",
    "# \"T2\": <ID>_{SAG | AX | COR}_[T1_ | T2_][3D_]FLAIR_[MIP_ | RECON_AVG_]<DOE>[_<tag>].nii\n",
    "# \"BOLD\": <ID>_BOLD_<DOE>.nii\n",
    "# Diffusion\n",
    "# \"ASL\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_info(sequence_name):\n",
    "    return (sequence_name.replace('-','_').replace('.','_').split('_'))[:-1]\n",
    "\n",
    "#selected everything expect the '.nii' part of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_standard(o_name):\n",
    "    n_name = o_name.replace('SAGITTAL', 'SAG').replace('CUBE', '3D').replace('AXIAL', 'AX').replace('CORONAL', 'COR')\n",
    "    \n",
    "    info=get_sequence_info(n_name)\n",
    "    \n",
    "    ID = info[0]\n",
    "    # ID does not follow designation [2-3 letter cohort designation][3-4 number designation]\n",
    "    match = re.match(r\"([A-Z]+)([0-9]+)\", ID, re.I)\n",
    "    if match:\n",
    "        parts = match.groups()\n",
    "        if parts[0] == 'WHITTIER':\n",
    "            n_name = n_name.replace('WHITTIER', 'WH')\n",
    "    \n",
    "    return n_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DOE(info):\n",
    "    if 'I' in info[-1]:\n",
    "        DOE=info[-2]\n",
    "        return(DOE[0:4]+\"/\"+DOE[4:6]+'/'+DOE[6:8])\n",
    "    else:\n",
    "        DOE=info[-1]\n",
    "        return(DOE[0:4]+\"/\"+DOE[4:6]+'/'+DOE[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_notes(sequence_info):\n",
    "    other = []\n",
    "    \n",
    "    for part in sequence_info:\n",
    "        if '(' not in part and ')' not in part:\n",
    "            other.append(part)\n",
    "\n",
    "    return other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plane(info):\n",
    "    if is_3D(info):\n",
    "        if 'SAG' in info: return 'FSPGR_3D_SAG'\n",
    "        elif 'COR' in info: return 'FSPGR_3D_COR'\n",
    "        elif 'AX' in info: return 'FSPGR_3D_AX'\n",
    "        else: return 'UNKNOWN'\n",
    "    else:\n",
    "        if 'SAG' in info: return 'FSPGR_SAG'\n",
    "        elif 'COR' in info: return 'FSPGR_COR'\n",
    "        elif 'AX' in info: return 'FSPGR_AX'\n",
    "        else: return 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_T1(file_name):\n",
    "    # TO-DO: how to handle \n",
    "    # 1) NEUROMELANIN scans\n",
    "    # 2) SE_MT\n",
    "    # 3) BRAVO\n",
    "    # 4) 2DTOF\n",
    "    # 5) repeat?\n",
    "    \n",
    "    sequence_info=get_sequence_info(file_name)\n",
    "    \n",
    "    if 'I' in sequence_info[-1]:\n",
    "        return None\n",
    "\n",
    "    ignore=['AVG', 'MIN', 'POST_PROCESS']\n",
    "    if any(word in file_name for word in ignore):\n",
    "        return None\n",
    "    \n",
    "    accept = ['SAG', 'AX', 'COR']\n",
    "    if sequence_info[1] not in accept:\n",
    "        return None\n",
    "    \n",
    "#     print(\"file name:\", file_name)\n",
    "    return file_name[:-4]+'.nii'\n",
    "\n",
    "    \n",
    "#TO-DO: repeated exam of the same date or at the different date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming to be estabilshed\n",
    "# <ID>_{SAG | AX | COR}_[T1_ | T2_][3D_]FLAIR_[MIP_ | MIN_IP_]<DOE>[_<tag>].nii\n",
    "def filt_FLAIR(sequence_name, flair_3d, flair_2d):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "            \n",
    "    if \"SAG\" in sequence_name:\n",
    "#         print(sequence_info)\n",
    "        if is_3D(sequence_name):\n",
    "            flair_3d.append(sequence_name)\n",
    "        else:\n",
    "            flair_2d.append(sequence_name)\n",
    "    elif 'AX' in sequence_name:\n",
    "#         print(sequence_info)\n",
    "        if is_3D(sequence_name):\n",
    "            flair_3d.append(sequence_name)\n",
    "        else:\n",
    "            flair_2d.append(sequence_name)\n",
    "    elif 'COR' in sequence_name:\n",
    "#         print(sequence_info)\n",
    "        if is_3D(sequence_name):\n",
    "            flair_3d.append(sequence_name)\n",
    "        else:\n",
    "            flair_2d.append(sequence_name)\n",
    "    else: \n",
    "#         print(\"\\t \", sequence_name)\n",
    "        return None\n",
    "            \n",
    "    sequence_name = '_'.join(sequence_info)+'.nii'\n",
    "    return sequence_name\n",
    "\n",
    "#TO-DO: T1 has 3D, 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming to be established:\n",
    "# \"T2\": <ID>_{SAG | AX | COR}_[3D_]T2_[<type>]<DOE>[_<tag>].nii\n",
    "def filt_T2(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "    \n",
    "    if \"SAG\" in sequence_name:\n",
    "        pass\n",
    "#         print(sequence_info)\n",
    "    elif 'AX' in sequence_name:\n",
    "        pass\n",
    "#         print(sequence_info)\n",
    "    elif 'COR' in sequence_name:\n",
    "        pass\n",
    "#         print(sequence_info)\n",
    "    else: \n",
    "#         print(\"\\t \", sequence_name)\n",
    "        pass\n",
    "        \n",
    "    return '_'.join(sequence_info)+'.nii'\n",
    "\n",
    "#TO-DO: T2 has difference pulse types :0 and some other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_diffusion(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)\n",
    "\n",
    "#TO-DO: this one will be A LOT OF FUN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOLD naming convention: <ID>_BOLD_<DOE>.nii\n",
    "def filt_bold(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "    \n",
    "    problem_bold = None\n",
    "    \n",
    "    sequence_info = ignore_notes(sequence_info)\n",
    "    sequence_name = '_'.join(sequence_info)+'.nii'    \n",
    "    \n",
    "    # The following ID's are the problem ones (from previous runs). Checking if these ID's are unique\n",
    "#     probs = ['SH005', 'WH1296', 'MEN009', 'WH1612', 'WH1268', 'MEN040', 'SH019', \n",
    "#              'MEN023', 'MEN007', 'WHITTIER5002']\n",
    "    \n",
    "    # If it contains EQ_1 or a letter attached to the end of the DOE,\n",
    "    # then there is a previous one that already exists\n",
    "    if sequence_info[-2] == 'EQ' or not sequence_info[-1].isdigit():\n",
    "        return None\n",
    "        \n",
    "#     elif ID in probs:\n",
    "#         problem_bold = sequence_name\n",
    "    \n",
    "    elif len(sequence_info) != 3:\n",
    "        problem_bold = sequence_name\n",
    "    \n",
    "#     return problem_bold\n",
    "    return sequence_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_asl(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)            \n",
    "    sequence_info=ignore_notes(sequence_info)\n",
    "    if not sequence_info[-1].isdigit():\n",
    "        return None\n",
    "#     print(sequence_info)\n",
    "    return '_'.join(sequence_info)+'.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_csf(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)\n",
    "\n",
    "#TO-DO: CSF of different location and CINE ON/OFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_carotid(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_aorta(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_candy_cane(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_arch(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_mpr(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_cbf(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filt_probe(sequence_name):\n",
    "    sequence_info=get_sequence_info(sequence_name)\n",
    "#     print(sequence_name)\n",
    "    print(sequence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(root):\n",
    "    \n",
    "    t1=[]\n",
    "    bold = []\n",
    "    flair = []\n",
    "    flair_3d = []\n",
    "    flair_2d = []\n",
    "    t2 = []\n",
    "    asl=[]\n",
    "    change = 0\n",
    "    counter=0\n",
    "    \n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            file_upper=base_standard(file.upper())\n",
    "            if fnmatch.fnmatch(file_upper, '*T1*NII') or fnmatch.fnmatch(file_upper, '*FSPGR*NII'):                 \n",
    "                n_file=filt_T1(file_upper)\n",
    "#                 print(\"T1:\", n_file)\n",
    "                if n_file is not None:\n",
    "                    t1.append((file, n_file))\n",
    "#                     if file != n_file:\n",
    "#                         #TODO: rename file\n",
    "#                         print(file, '-->', n_file)\n",
    "#                 pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*FLAIR*NII'): \n",
    "#                 print(\"FLAIR: \\t\", file_upper)\n",
    "                n_file = filt_FLAIR(file_upper, flair_3d, flair_2d)\n",
    "#                 print(\"FLAIR:\", n_file)\n",
    "                if n_file is not None:\n",
    "                    flair.append((file, n_file))\n",
    "#                     if file != n_file:\n",
    "#                         #TODO: rename file\n",
    "#                         print(file, '-->', n_file)\n",
    "#                 pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*T2*NII'):\n",
    "#                 print('\\t', file_upper)\n",
    "                n_file = filt_T2(file_upper)\n",
    "                if n_file is not None:\n",
    "                    t2.append((file, n_file))\n",
    "#                     if file != n_file:\n",
    "#                         #TODO: rename file\n",
    "#                         print(file, '-->', n_file)\n",
    "#                 pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*BOLD*NII'):\n",
    "                n_file = filt_bold(file_upper)\n",
    "                if n_file is not None:\n",
    "#                     print(file, '-->', n_file)\n",
    "                    bold.append((file, n_file))\n",
    "#                     if file != n_file:\n",
    "#                         #TODO: rename file\n",
    "#                         print(file, '-->', n_file)\n",
    "#                 pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*DTI*NII') or fnmatch.fnmatch(file_upper, '*DKI*NII') or fnmatch.fnmatch(file_upper, '*DIFF*NII') or fnmatch.fnmatch(file_upper, '*DWI*NII') or fnmatch.fnmatch(file_upper, '*AVER*DC*NII') or fnmatch.fnmatch(file_upper, '*FRACT*ANISO*NII'):\n",
    "#                 print('\\t', file_upper)\n",
    "#                 sort_diffusion(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*ASL*NII'):\n",
    "                n_file=filt_asl(file_upper)\n",
    "                if n_file is not None:\n",
    "                    asl.append((file, n_file))\n",
    "#                     if file != n_file:\n",
    "#                         #TODO: rename file\n",
    "#                         print(file, '-->', n_file)\n",
    "#                 pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*SWAN*NII'):\n",
    "                # This file has no discrapency!!!!!!!!!!!!! for right now\n",
    "#                 print('SWAN', file_upper)\n",
    "#                 filt_swan(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*CSF*NII'):\n",
    "#                 print('CSF:', file_upper)\n",
    "#                 filt_csf(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*CAROTID*NII'):\n",
    "#                 print('Carotid:', file_upper)\n",
    "                pass\n",
    "#                 filt_carotid(file_upper)\n",
    "            elif fnmatch.fnmatch(file_upper, '*AORTA*NII'):\n",
    "#                 print(file_upper)\n",
    "#                 filt_aorta(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*CEREBR*BLOOD*FLOW*NII'):\n",
    "#                 print(file_upper)\n",
    "#                 filt_cbf(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*MPR*NII'):\n",
    "#                 print(file_upper)\n",
    "#                 filt_mpr(file_upper)\n",
    "                pass\n",
    "            elif 'LOC' not in file_upper and fnmatch.fnmatch(file_upper, '*CANDY_CANE*NII'):\n",
    "                print('Candy cane:', file_upper)\n",
    "#                 filt_candy_cane(file_upper)\n",
    "                pass\n",
    "            elif 'LOC' not in file_upper and fnmatch.fnmatch(file_upper, '*ARCH*NII'):\n",
    "#                 print(file_upper)\n",
    "#                 filt_arch(file_upper)\n",
    "                pass\n",
    "            elif 'LOC' not in file_upper and fnmatch.fnmatch(file_upper, '*PROBE*NII'):\n",
    "#                 print(file_upper)\n",
    "#                 filt_probe(file_upper)\n",
    "                pass\n",
    "            elif fnmatch.fnmatch(file_upper, '*NII'):\n",
    "#                 print('\\t', file_upper)\n",
    "                pass\n",
    "            else:\n",
    "#                 print('\\t\\t', file_upper)\n",
    "                pass\n",
    "\n",
    "#     print(len(T1))\n",
    "#     print(\"counter: \", counter)\n",
    "#     print(len(asl))\n",
    "#     print(len(bolds))\n",
    "#     for pair in bolds:\n",
    "#         print(pair)\n",
    "#     print(len(flair))\n",
    "#     print(len(flair_3d))\n",
    "#     print(len(flair_2d))\n",
    "#     print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     source_dir=input(\"Enter source dir:\")\n",
    "    source_dir=\"/Users/baymac/Desktop/Project_NaCl_Test_DataSet/3T_Last_updated_31OCT19KW\"\n",
    "#     source_dir = '/media/ke/8tb_part2/FSL_work/all_info'\n",
    "    get_path(source_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candy cane: WH1720_CANDY_CANE_20190923161210A.NII\n",
      "Candy cane: WH1720_CANDY_CANE_20190923161210B.NII\n",
      "Candy cane: WH1720_CANDY_CANE_20190923161210.NII\n",
      "Candy cane: WH1743_CANDY_CANE_20191008102726.NII\n",
      "Candy cane: WH1708_CANDY_CANE_20190528130005.NII\n",
      "Candy cane: WH1769_CANDY_CANE_20191023141845.NII\n",
      "Candy cane: WH1769_CANDY_CANE_20191023141845A.NII\n",
      "Candy cane: WH1372_CANDY_CANE_20190604102741A.NII\n",
      "Candy cane: WH1372_CANDY_CANE_20190604102741.NII\n",
      "Candy cane: WH1728_CANDY_CANE_20190716110139.NII\n",
      "Candy cane: WH1280_CANDY_CANE_20190514094350.NII\n",
      "Candy cane: WH1723_CANDY_CANE_20190530130600A.NII\n",
      "Candy cane: WH1723_CANDY_CANE_20190530130600.NII\n",
      "Candy cane: WH1487_CANDY_CANE_20190712112737.NII\n",
      "Candy cane: WH1487_CANDY_CANE_20190712112737A.NII\n",
      "Candy cane: WH1738_CANDY_CANE_20190715094319.NII\n",
      "Candy cane: WH1737_CANDY_CANE_20190708090335.NII\n",
      "Candy cane: WH1333_CANDY_CANE_20191105094123.NII\n",
      "Candy cane: WH1736_CANDY_CANE_20190708103024.NII\n",
      "Candy cane: WH1736_CANDY_CANE_20190708103024A.NII\n",
      "Candy cane: WH1736_CANDY_CANE_20190708103024B.NII\n",
      "Candy cane: WH1488_CANDY_CANE_20191022102404A.NII\n",
      "Candy cane: WH1488_CANDY_CANE_20191022102404.NII\n",
      "Candy cane: WH1727_CANDY_CANE_20190603131028.NII\n",
      "Candy cane: WH1721_CANDY_CANE_20190813110806.NII\n",
      "Candy cane: WH1331_CANDY_CANE_20190514132222.NII\n",
      "Candy cane: WH1741_CANDY_CANE_20190626135539.NII\n",
      "Candy cane: WH1741_CANDY_CANE_20190626135539A.NII\n"
     ]
    }
   ],
   "source": [
    "if __name__ ==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
